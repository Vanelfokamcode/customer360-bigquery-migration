# Customer 360 Legacy System Analysis

## üè¢ Vue d'ensemble

**Plateforme actuelle :** PostgreSQL 14 (local, Docker)
**Volume de donn√©es :** ~5,000 clients
**Architecture :** 3-layer data warehouse

### Pourquoi 3 couches ?

1Ô∏è‚É£ **RAW** (Donn√©es brutes)
   - Ce qui arrive directement des CSV
   - AUCUNE transformation
   - Exemple : email = "  JOHN@GMAIL.COM  " (espaces, majuscules)

2Ô∏è‚É£ **STAGING** (Nettoyage)
   - Normalisation : email = "john@gmail.com"
   - Validation : is_valid_email = TRUE/FALSE
   - Parsing des dates : "2023-01-15" ‚Üí DATE

3Ô∏è‚É£ **WAREHOUSE** (Analytics)
   - Agr√©gations business : RFM scores, Health scores
   - Dimensions : dim_customers (table de r√©f√©rence)
   - M√©triques : cohort_retention (analyse de r√©tention)

---

## üì¶ Inventaire des Tables

### RAW Layer (3 tables)
| Table | Contenu | Rows |
|-------|---------|------|
| `raw.csv_customers` | Donn√©es clients brutes | 5,437 |
| `raw.csv_orders` | Transactions brutes | ~15,000 |
| `raw.csv_products` | Catalogue produits | ~500 |

### STAGING Layer (3 tables)
| Table | Transformation | Output |
|-------|---------------|--------|
| `stg_csv_customers` | Email normalis√©, dates pars√©es | 5,437 |
| `stg_csv_orders` | Montants valid√©s, dates | ~15,000 |
| `stg_csv_products` | Prix nettoy√©s | ~500 |

### WAREHOUSE Layer (4 tables)
| Table | Business Logic | Insight |
|-------|---------------|---------|
| `dim_customers` | D√©duplication (5,437 ‚Üí 4,501) | Clients uniques |
| `customer_rfm` | Segmentation RFM | 450 VIPs, 800 Champions |
| `customer_health` | Score de sant√© (0-100) | Qui va churner ? |
| `cohort_retention` | Cohortes mensuelles | Taux de r√©tention |

---

## üßÆ Business Logic Cl√© √† Pr√©server

### 1. D√©duplication (Identity Resolution)

**Probl√®me :** Jean ach√®te avec "jean@gmail.com", puis "JEAN@GMAIL.COM"
‚Üí PostgreSQL voit 2 clients diff√©rents !

**Solution actuelle :**
```sql
-- Normaliser l'email
email_normalized = LOWER(TRIM(email))

-- Cr√©er une cl√© unique
identity_match_key = MD5(email_normalized)

-- Garder seulement le premier achat
ROW_NUMBER() OVER (PARTITION BY identity_match_key ORDER BY created_at)
```

**R√©sultat :** 5,437 rows ‚Üí 4,501 clients uniques

---

### 2. RFM Segmentation

**RFM = Recency, Frequency, Monetary**

**Analogie du restaurant :**
- **Recency** : Derni√®re visite il y a combien de temps ?
  - 7 jours = client actif (score 5)
  - 6 mois = client perdu (score 1)

- **Frequency** : Combien de visites cette ann√©e ?
  - 50 fois = client fid√®le (score 5)
  - 2 fois = occasionnel (score 1)

- **Monetary** : Combien d√©pens√© au total ?
  - ‚Ç¨10,000 = gros client (score 5)
  - ‚Ç¨50 = petit client (score 1)

**Segments :**
```
VIP       : R‚â•4, F‚â•4, M‚â•4  (Vient souvent, d√©pense beaucoup, r√©cent)
Champion  : R‚â•4, F‚â•3       (Tr√®s actif)
Loyal     : R‚â•3, F‚â•3       (Fid√®le mais moins actif)
At Risk   : R‚â§2, F‚â•3       (√âtait fid√®le, mais parti !)
Lost      : R‚â§2, F‚â§2       (Compl√®tement inactif)
```

**Dans ton dataset :**
- 450 VIPs (10% des clients = 90% du revenu !)
- 800 Champions
- 200 "At Risk" ‚Üí Marketing doit les r√©activer !

---

### 3. Health Score

**Formule :**
```
Health Score = (Recency √ó 25) + (Frequency √ó 25) + (Monetary √ó 30) + (Email Valid √ó 20)
```

**Pourquoi ces poids ?**
- **Monetary = 30%** : Le plus important = combien ils d√©pensent
- **Recency = 25%** : S'ils sont partis = danger !
- **Frequency = 25%** : Fid√©lit√©
- **Email Valid = 20%** : Si email invalide = on ne peut pas les recontacter !

**Classification :**
- Excellent (‚â•80) : VIPs en bonne sant√©
- Good (‚â•60) : OK
- Fair (‚â•40) : √Ä surveiller
- At Risk (<40) : DANGER ‚ö†Ô∏è

---

## üö® Probl√®mes de Qualit√© Identifi√©s

### 1. Emails Malform√©s (63 cas)
```
Invalides :
- "john@" (pas de domaine)
- "@gmail.com" (pas de nom)
- "john.doe" (pas de @)
- "test@test" (domaine invalide)
```

### 2. Doublons (436 cas)
```
jean@gmail.com   ‚Üí 3 fois
marie@yahoo.fr   ‚Üí 2 fois
...
Total : 5,437 rows ‚Üí 4,501 uniques
```

### 3. Dates Mixtes (3 formats !)
```
Format 1: "2023-01-15"      (ISO 8601)
Format 2: "15/01/2023"      (europ√©en)
Format 3: "01-15-2023"      (am√©ricain)
```

**Solution actuelle :** Macro `parse_mixed_dates()` qui essaie les 3 formats

---

## üîÑ PostgreSQL ‚Üí BigQuery : Traductions N√©cessaires

### Syntaxe SQL

| PostgreSQL | BigQuery | Pourquoi ? |
|-----------|----------|-----------|
| `::DATE` | `CAST(x AS DATE)` | BigQuery n'aime pas `::` |
| `~` (regex) | `REGEXP_CONTAINS()` | Fonction diff√©rente |
| `VARCHAR(255)` | `STRING` | BigQuery = pas de limite de taille |
| `SERIAL` | `INT64` | Pas d'auto-increment |

### Exemple Concret

**PostgreSQL :**
```sql
SELECT 
  email::VARCHAR,
  created_at::DATE,
  CASE WHEN email ~ '^[A-Z]' THEN TRUE ELSE FALSE END
FROM raw.csv_customers;
```

**BigQuery :**
```sql
SELECT 
  CAST(email AS STRING),
  CAST(created_at AS DATE),
  REGEXP_CONTAINS(email, r'^[A-Z]')
FROM `customer360-migration.raw_data.csv_customers`;
```

---

## üìà M√©triques de Succ√®s

**La migration est r√©ussie si :**

‚úÖ **Exactitude** : 4,501 clients uniques (m√™me nombre qu'avant)
‚úÖ **RFM** : 450 VIPs (pareil)
‚úÖ **Revenue** : ‚Ç¨1.8M total (pareil)
‚úÖ **Performance** : Queries <100ms (vs 500ms en PostgreSQL)
‚úÖ **Co√ªt** : ‚Ç¨0 (free tier BigQuery)

---

## üéØ Conclusion

**Ce qu'on migre :**
- 10 tables
- 20,000+ rows au total
- 3 couches (raw ‚Üí staging ‚Üí warehouse)
- Business logic complexe (RFM, dedup, health scoring)

**Ce qu'on DOIT pr√©server :**
- M√™me nombre de clients uniques
- M√™me segmentation RFM
- M√™me logique de d√©duplication

**Ce qu'on va am√©liorer :**
- Performance (clustering, partitioning)
- Scalabilit√© (cloud vs local)
- Co√ªt (‚Ç¨0 vs serveur)
